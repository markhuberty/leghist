%\documentclass[14pt]{extarticle}
\documentclass[11pt]{article}
\usepackage{natbib}
\usepackage[dvipdfm,colorlinks=true,urlcolor=DarkBlue,linkcolor=DarkBlue,bookmarks=false,citecolor=DarkBlue]{hyperref}

\usepackage[pdftex]{graphicx}
\usepackage{fancyhdr}
\usepackage[T1]{fontenc}
\usepackage{palatino}
\usepackage[utf8]{inputenc}
%\usepackage[super]{nth}
\usepackage{setspace}
\usepackage{placeins}
\usepackage{subfigure}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{marvosym}  % Used for euro symbols with \EUR
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\usepackage{longtable} %% Allows the use of the longtable format produced by xl2latex.rb
\usepackage{lscape} %% Allows landscape orientation of tables
\usepackage{appendix} %% Allows customization of the appendix properties
\setcounter{tocdepth}{1} %% Restricts the table of contents to the section header level entries only

\usepackage{geometry}
\geometry{letterpaper}
\usepackage{amsmath}
\usepackage[stable]{footmisc}

%% The following settings are for the listings environment in R
\usepackage{listings}
\usepackage[svgnames]{xcolor}
\usepackage{soul}
\sethlcolor{LightGoldenrodYellow}
\lstset{backgroundcolor=\color{LightYellow}}
\lstset{framextopmargin=6pt, framexbottommargin=6pt, framerule=4pt, rulecolor=\color{White}}

\title{\texttt{leghist}:\\ Automated legislative history analysis for
  R\thanks{Original version: 30 January 2012. Thanks to Adrienne Hosek for discussions on the
  comparative legislative processes for the United States Congress and
the European Parliament.}}
\author{Mark Huberty\thanks{Travers Department of Political Science,
    University of California, Berkeley. Contact:
    \url{markhuberty@berkeley.edu}.}~ and Hillary Sanders\thanks{University of
California, Berkeley.}}
\date{\today}

\graphicspath{{../figures/}}

\begin{document}
%\input{/Users/markhuberty/Documents/Technology/Documentation/Typesetting/prospectusTitle.tex}
\maketitle
%\doublespacing

\begin{abstract}
  We describe an integrated workflow for automated analysis of
  legislative history in the R language. Legislative history analysis
  often requires laborious hand-matching of proposed amendments and
  their authors to their destination in a final bill. \texttt{leghist}
  deploys natural language and textual analysis methods to automate
  matching, estimate match accuracy, model the
  semantic content of amendments, tabulate the rate of acceptance and
  rejection of amendments by legislative actor and topic, and visualize the
  resulting flow of information. We provide a theoretical
  overview of the workflow and suggest this model could be extended to
  other analagous forms of legal and political document analysis. We
  finally provide a vignette based on the European Union's Third
  Renewable Energy Directive, adopted in 2008. 
\end{abstract}

\section{Introduction}
\label{sec:introduction}

Analysis of legislative history plays a central role in political
science. The data often present barriers to making straightforward, or
quantifiable progress. Few legislatures provide marked-up versions of final bills
indicating when and how proposed legislation was amended, or by
whom. Particularly for very large bills with many amendments,
identifying these important sources of information on legislative
influence and process constitute a very large search problem. 

Here, we provide tools to automate the process of legislative history
analysis. The \texttt{leghist} package for R provides tools for
processing text from proposed legislation and amendments, matching
sections of the final bill to their most likely origin in either the
proposed bill or subsequent amendments, and quantifying the degree and
from of variation among both successful and unsuccessful
amendments. We show, through hand-coded trials, that the unsupervised
methods used here generate valid matches at a high degree of accuracy
in terms of both human-identified textual similarity and evidence from
the formal legislative record. Finally, we emphasize that the tools
provided here should work for other document history processes
analagous to the legislative history model we present below.

\section{How a bill becomes a law: a model}
\label{sec:how-bill-becomes}

The tools presented here implement an abstracted view of how a bill
becomes a law. This section presents this stylized model in three,
increasingly complex, steps. The biggest change imposed by the added
complexity concerns whether we should use supervised or unsupervised
methods to identify the origin of the components of the final
bill. While the most basic case permits a purely unsupervised
approach, the more complex cases benefit from some additional user
input. The tools provided in the
\texttt{leghist} package assist the analyst in making progress on both
the most basic case and each extension. 

We may raise a set of questions that we want to answer with regard to
the history of a bill as it evolves through a legislative process:
\begin{itemize}
\item Which sections of the original bill survived to the final version?
\item Which amendments were adopted, and which weren't?
\item Who originated the adopted amendments, versus those not adopted?
\item What was the content of the amendments, and does that content
  categorize in systematic ways (i.e., did amendments focus on
  particular topics within the policy domain)?
\item Were there aspects of the final bill that have no good match,
  suggesting changes made behind the scenes (i.e., in the
  reconcilliation process between the House and Senate in the United States Congress)
\end{itemize}


\subsection{The simple model: a pure legislative process}
\label{sec:simple-model:-pure}

We treat a bill as a document $D$ composed of $I$ sections $d_i$. The
legislative process begins with an initial bill $D_1$, and concludes
with a successful bill $D_2$. During the legislative process, $J$
amendments $a_j \in A_J$ are
proposed by some set of legislative actors $L$, of which $A_K, K \leq
J$ are adopted. For $D_1, D_2,$ and $A_J$, we assume that the sections
$d_{1,i}, d_{2,i}$, and $a_j$ are all at the same level of
disaggregation. The tools presented here are agnostic to that level of
disaggregation, but for the rest of this paper we assume that sections
are analagous to paragraphs. This is consistent with the structure of
amendments for the European Parliamentary bills considered in section
\ref{sec:vign-2009-europ}.

For the simple case, then, the final bill is a
combination of the proposed bill and the proposed
amendments. We can represent that process as a functional form of $D_2
= f(D_1, A_J)$. Each section $d_{2,i}$ contains one and only one best
match in $D_1, A_j$. Given that, the challenge is to identify the sections
of the original bill and the amendments that comprise the final
bill. 

We can thus define a similarity measure $S$ to permit comparison
between the final bill and its potential origins. For simiplicity, we
assume that $S \in [0,1]$. For each final section $d_{2,i}$ we
construct a similarity vector $s_i$ between all possible matches in
$D_1, A_J$. The best match is thus $d \in arg \max_{s_i} S(D_1,
A_J)$. Under the assumption that $S$ is well-ordered, we can use
nearest-neighbor matching, since for each $d_{2,i}$ there is one and
only one best match.\footnote{Of course, a distance metric can also be
used, in which case the choice problem becomes $d \in arg \min_{s_i}
S(D_1, A_J)$.}

To construct the distance metric, we first construct a vector-space
representation of each section of $D_2$, $D_1$, and $A_j$, using a
common dictionary. Given that vector-space representation of the
language used in the final bill and all candidate matches, we can
construct the similarity measure using any continuously-valued
similarity or distance metric.

\subsection{Extensions: fuzzy matches}
\label{sec:extens-fuzzy-match}

The first extension to this stylized legislative process involves a
set of fuzzy potential matches. Two possible developments will lead to
fuzzy matches. First, specific language in a bill, such as
cross-references to other bill sections, dates, or formal legal
language, may change without affecting the substantive semantic
content of the bill section and its best match. Second, the drafting
process may split apart and recombine sections prior to the final
bill, without necessarily affecting the origin of the legislative
language.\footnote{We also note that this set of changes may be
  introduced by the process of producing machine-readable text. Given
  that much of this text must be scraped by the analyst, this form of
  variation may be introduced by the scraping algorithm
  itself. Validating the algorithm for each bill represents a
  significant effort that we would like the analyst to avoid.} We would wish to identify both cases.

Nearest-neighbor matching with replacement handles both
problems. Matching with replacement permits a single amendment to
match to multiple sections of the final bill. This same approach also works for subtle changes in language
introduced during final drafting of the bill. For instance, consider
the final section of a bill (left) and the initial section of a bill
(right) presented as below:
\begin{quote}
  \begin{minipage}[t]{0.45\linewidth}
    to develop renewable energies to meet the commitment of the Com-
    munity to using 20\% renewable energies by 2020, as well as to
    develop other technologies contributing to the transition to a
    safe and sustainable low-carbon economy and to help meet the commitment of the Community to increase energy effciency by 20\% by
    2020;
  \end{minipage}
  \begin{minipage}[h]{0.08\linewidth}
  \end{minipage}
  \begin{minipage}[t]{0.45\linewidth}
    to develop renewable energies to meet the commitment of the Com-
    munity to using 20\% renewable energies by 2020, and to meet the
    commitment of the Community to increase energy effciency by 20\%
    by 2020;
  \end{minipage}
\end{quote}

Here, the use of nearest-neighbor matching does not require the exact
match between the final bill section and its candidate
sources. Rather, so long as the similarity measure produces a
well-ordered similarity vector, the match will return the correct value.

It is important to note one situation in which this matching process
breaks down. Introduction of the same amendment by multiple
legislative actors will produce more than one match, since the
similarity vector is no longer well-ordered. Absent additional
information, it is impossible to determine which is the ``correct''
match from this set. Thus the algorithm may return the correct
\textit{semantic} origin without necessarily returning the correct
\texttt{procedural} origin. We will return to this issue when we discuss
supervised processes.

\subsection{Extensions: negotiated content and revisions}
\label{sec:extens-negot-cont}

Finally, some legislative processes may not require that all changes
to a bill be introduced as formal amendments. This is particularly
true where negotiated outcomes are common. Examples here include the
reconciliation process in the United States Congress, and the
co-decision process between the European Parliament and Council. In
this case, substantial changes to a bill may occur without any
matching record in either the original bill or the proposed
amendments. 

Given that the nearest-neighbor process defined above will return some
match even if no actual match exists, handling this case requires a
filter for ``poor'' matches. We implement this process with a filter
on the similarity measure itself: for matches whose similarity
measure $s$ is below a user-supplied threshold $T$, we reject the
match and instead match the section to itself. This ``false'' match
can aid the identification of elements in a bill that
came out of negotiated rather than formal amendment processes. 

The use of a similarity threshold raises the question of how to set
that threshold. Too high a threshold will correctly identify all ``unsourced'' bill
sections, but throw out accurate matches. Likewise, too low a threshold
will reduce match quality and lead to potentially incorrect
inferences. This leads to two different measures of match accuracy,
which we refer to as Type 1 and Type 2 measures for their analogues in
Type 1 and Type 2 errors. Type 1 accuracy measures the share of
correctly attributed actual matches, while Type 2 measures the share
of correctly attributed ``false'' matches. Raising the threshold value
$T$ will increase Type 2 accuracy while harming Type 1
accuracy.  

We propose that balancing the Type 1 / Type 2 tradeoff can be treated
as a supervised learning problem
in which the optimal $T$ is derived from a set of user-coded data. We
provide tools to automate the hand-matching of a random subset of the
final bill to its potential sources. Based on that hand coding, the
proper threshold value can be chosen to maximize the accuracy of the
matching algorithm. We provide the capability to estimate the optimal
$T$ based on both overall accuracy and the tradeoff of Type 1 and Type
2 errors. 


\section{The technical implementation}
\label{sec:legisl-sect-match}



\subsection{Matching and visual comparison}
\label{sec:match-visu-comp}

Given the model presented in section \ref{sec:how-bill-becomes}, the
analytic problem thus becomes identifying which amendments and
portions of the initial bill become the final bill. We treat this as a
document retrieval problem, wherein we wish to query for a document
$D_{2,i}$ and retrieve its most likely match from $D_2,
A_J$. \footnote{This can, alternatively, be treated as a
subset of the plagiarism problem, wherein we know with probability
approaching one that $D_2$ has plagiarized content from $D_1$ and
$A_J$. As with other versions of plagiarism detection, the problem
then becomes establishing an effective and efficient comparison
strategy.}

We implement a generic comparison strategy in four steps:
\begin{enumerate}
\item Transform each section of $D_2$, $D_1$, and $A_J$ into a
  bag-of-words vector-space representation in which features are
  n-grams of potentially heterogeneous length
\item Construct the pairwise similarity, using some similarity metric,
  between each section of $D_2$ and all sections in $D_1$ and $A_J$.
\item Use nearest-neighbor matching with replacement to establish
  the closest match between each section of $D_2$ and a section in
  $D_1$ and a candidate amendment in $A_J$
\item Pick the closest match of the pair of potential matches $d_i$
  and $a_j$
\end{enumerate}

Implementation of step (1) occurs via the \texttt{tm} package for R \citep{meyer2008text},
and uses the Weka tokenizer for term
tokenization \citep{hall2009weka}. This infrastructure provides users the ability to
specify whether words should be stemmed; whether punctuation, excess
whitespace or stopwords should be
removed; the minimum and maximum n-gram length used for constructing the vector space
representation of text, and whether the term list should be filtered
on the basis of one of several metrics including term-frequency and
term frequency / inverse document frequency measures. 

The \texttt{leghist} package comes with several alternative distance metrics for use
in step (2). For token-based distance metrics, we implement a standard cosine similarity, a
length-weighted cosine similarity, and a length-weighted joint
information distance measure as described by \cite{hoad2003methods}. In plagiarism applications, length-sensitive
distance metrics have performed well in identifying correct documents
from otherwise quite similar candidate matches. However,
the matching process here appears to favor the fuzzy matches provided
by the length-insensitive cosine similarity. This may, as we will discuss, be due to the
somewhat arbitrary choice of what constitutes a document section, and
its instability over time. Finally, the function interfaces allow the
user to supply any distance function so long as it returns a
correctly-formatted distance matrix. We also implement an interface to
string-based metrics like the Levenshtein edit distance \citep{elmagarmid2007}.

Step (3) uses simple nearest neighbor matching with replacement to
identify the most likely candidate matches from both the initial
document and the set of proposed amendments. Both matches are returned in an
intermediate step to permit users to identify the connection to the
initial bill and to the potential amendments. Finally, under the
assumption that the similarity metric is consistent and well-ordered, we can then in step (4) compare
this pair of potential matches to determine the best potential match
from all candidate matches. 

Based on the pairwise matches between sections in the final bill and
the set of potential sources for the final version of those sections,
we can construct a synthetic bill for comparison purposes. The package
provides tools to construct a side-by-side comparison of the final
bill sections to their candidate matches. If the user supplies a
non-zero threshold value as described in section
\ref{sec:extens-negot-cont}, that
value is used to determine whether the actual match
should be used. If the threshold value is not met, then the final
document section is matched to itself. 

Finally, \texttt{leghist} provides an interface to output the matched
document as a two-column \LaTeX\ document, which can be directly
compiled into a PDF. Within that document, each paragraph of the final
bill is shown side-by-side with its match. Words differences between
the paragraphs are highlighted as colored text. 

\subsection{Semi-supervised learning of the optimal threshold value}
\label{sec:superv-learn-optim}

Selection of an optimum threshold value will depend on the specifics
of the legislative process behind each bill. For instance, the right
threshold value for a bill that was modified only via the amendment
process may be much lower than a threshold value valid for a bill that
went through a negotiation or reconcilliation process. While our experiments
suggest that values on the order of 0.3 perform reasonably well, we
recommend that users base threshold selection on the performance of
the matching algorithm in their particular case. For instance,
legislative procedures known to have significant negotiated content
may benefit from a higher threshold value, while those with very
little negotiated content might require a threshold value close to
0. To facilitate identification of context-specific thrshold values, we provide tools that allow the user to
hand-code a subset of a given bill and derive the optimum threshold
value based on the algorithm's performance against that hand-coded
data. In practice, coding of 30\% of a bill appears sufficient to
derive acceptable threshold values.

Figure \ref{fig:bill-accuracy-curves} provides an example of the
performance of the document retrieval process as established by this
semi-supervised approach. For each of four different bills, 30\% of
the final bill was hand-matched to the most semantically appropriate
sources in either the original draft of the bill or
subsequently-proposed amendments. Based on this sub-sample, we
established the optimum threshold based on both overall accuracy and
the tradeoff between Type 1 and Type 2 errors. In all cases, the
optimum threshold lay between 0.3-0.45. The variation in the optimum
threshold setting appears to derive from two primary sources: the
degree of negotiation (as opposed to formal amendment) in the
legislative process itself; and the amount of structural change that
occurred when amendments were incorporated into formal legislative language.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.45\textwidth]{ets_2003_accuracy_curves}
  \includegraphics[width=0.45\textwidth]{ets_2007_accuracy_curves}
  \includegraphics[width=0.45\textwidth]{intl_2003_accuracy_curves}
  \includegraphics[width=0.45\textwidth]{rese_2007_accuracy_curves}
  \caption{Accuracy assessment curves for 30\% training samples in
    each of four different bills. Bills were drawn from the European
    Union in years 2001, 2003, and 2007. Optimum threshold values
    ranged from 0.3-0.4 in all cases.}
  \label{fig:bill-accuracy-curves}
\end{figure}

\subsection{Amendment content analysis and clustering}
\label{sec:amendm-cont-analys}

Finally, the legislative process rarely amends bills at
random. Rather, specific sections or issue areas within bills will
often prove more contentious than others. The user may wish to
identify these areas on the basis of accepted and rejected amendments,
sections of the original bill that persist to the final bill, and
sections of the final bill for which no match was identified. 

We provide a ready interface between the matched bill and the
\texttt{topicmodels} package for R that enables topic modeling of
these different slices of the matched bill. As described by
\cite{blei2003latent}, topic modeling assumes a latent
structure within a set of documents. Each document--in this case, a
bill section--is assumed to derive from a mixture of topics. Each
topic, in turn, is represented by distribution over a
set of terms. Latent Dirichlet Allocation provides a Bayesian method
for inferring topics from empirical word distributions, and assigning
documents to those topics on the basis of document-specific
distributions. 

\subsection{Macro-scale amendment visualization}
\label{sec:macro-scale-vis}

Finally, \texttt{leghist} provides an interface to visualize the
macro-scale development of a bill in terms of amendment and topic
flow. Amendment flow is treated as a directed acyclic graph, in which
nodes can be legislative actors, semantic topics, and amendment
status. Implementation uses the \texttt{igraph} library. Two types of acyclic directed graphs are facilitated:

\begin{enumerate}
\item The flow of amendments from the committees which originated
  them, to final status as either accepted or rejected components of
  legislation (via \texttt{PlotCommitteeTopics}). This is modeled as a tripartite acyclic graph in which
  nodes are legislative actors, semantic topics, and final
  status. Edges represent the flow of amendments via topics to final
  status. Edgewidth corresponds to the volume of amendments by source
  or destination, and edge color codes for . Node size is proportional
  to the count of amendments passing originating from or passing
  through each nodes. For topic nodes, the top $N$ terms for each
  topic are printed alongside the node itself.
\item The failure, or the success and placement (index) in the final
  bill, of each submitted amendment is modeled by a three tiered
  directed acyclic graph (via \texttt{PlotAmendsSuccess}). Each amendment, represented by an individual node in the bottom tier, is connected to its final destination - either a junk bin in the middle tier of the graph, or the amendment's placement in the final bill, each paragraph of which is represented as an individual node in the top and final tier. Arrow colors represent either an amendment's topic or committee.
\end{enumerate}

The first graph provides for easy macro-scale visualization of the
flow of amendments. The second provides a rapid way to establish the
correspondence between topics and bill sections, and to identify the
distribution of bill modifications as represented in the final
bill. plotting facilities in \texttt{leghist} provide significant
flexibility to control the information encoded in the color, size, and
transparency of nodes and edges in each graph. Examples of each are provided in section
\ref{sec:content-modeling}. 


\section{Vignette: the 2009 European Electricity Market Regulation }
\label{sec:vign-2009-europ}

To illustrate each of these tools and their technical underpinnings,
we now provide a vignette based on actual legislation as passed by the
European Parliament. In 2008, the European Commission proposed a new round of reforms to
the regulation of European electricity markets. This reform followed
on the first (1996) and second (2003) internal market directives. Each
aimed to break up the vertically integrated utilities that dominated
national electricity markets, facilitate cross-border market
integration, and support greater consumer choice over energy
suppliers. The reforms also played a facilitating role for the
incorporation of greater amounts of renewable energy into Europe's
electricity supply. 

The original bill in this case was a package of amendments to the 2003
legislation proposed by the European Commission as Commission document
COM 2007 (528). Based on this document, the European Parliament
introduced a first round of amendments through its First Reading. On
the basis of that document, the European Council subsequently
negotiated a Common Position. This replaced the Commission's
legislative proposal as a complete bill. The Parliament subsequently
amended this further, in a Second Reading. The final bill was
adoped as Directive 2009 (72).\footnote{A full procedural record can
  be found at
  \url{http://www.europarl.europa.eu/oeil/popups/ficheprocedure.do?reference=2007/0195(COD)&lg=fr}. Referenced
12 February 2012.} 

This section demonstrates the operation of the \texttt{leghist}
package in analyzing the amendment process for this legislation. We
treat the initial bill as the 2003 legislation which the Commission
proposed to change. Amendments then constitute the Commission proposal
and the amendments contained in the First and Second Reading
Reports. We do not treat the Council Common Position as a set of
amendments, as it was released as a complete bill with no indication
of where the Council had amended it. Instead, we use this as a feature
to demonstrate the ability of the \texttt{leghist} package to reveal
changes not represented in formal amendments. 

We begin by reading in the bills and amendments as plain text. In each
case, the bills had been parsed from original documents available from
the European Legislative Observatory. We note that neither the bills
nor the amendments were
not available in easily machine-readable format. We provide more
detail on how the available electronic records were parsed into
machine-readable plain text in appendix (). 

\begin{lstlisting}[language=R, numbers=none]
ep.first.reading <- 
  read.csv("./2007/txt/ep_first_reading_report.txt",
           header=TRUE,
           stringsAsFactors=FALSE
           )
ep.second.reading <-
  read.csv("./2007/txt/ep_second_reading_report.txt",
           header=TRUE,
           stringsAsFactors=FALSE
           )

initial.bill <- readLines("./2003/txt/directive_2003_54_ec.txt")
commission.proposal <- readLines("./2007/txt/com_2007_528_final.txt")
council.common.position <- readLines("./2007/txt/council_common_position.txt")
final.bill <- readLines("./2007/txt/directive_2009_72_ec.txt")
\end{lstlisting}

We then transform this set of documents into a single document-term
matrix containing a vector space bag-of-words representation of each
section of the bills and proposed amendments. Each row of the matrix represents one section of one document,
while the columns represent unique terms in those documents, and
matrix entries the term frequencies for those terms in each
document. In this case, we do not stem the terms, but do remove
English stopwords, excess whitespace, and punctuation. We also use
bigrams, on the supposition that the added semantic content of unique
2-consecutive-word combinations may give greater resolution.

\begin{lstlisting}[language=R, numbers=none]
doc.list <- CreateAllVectorSpaces(initial.bill,
                                  final.bill,
                                  c(ep.first.reading$text,
                                    ep.second.reading$text,
                                    commission.proposal
                                    ),
                                  ngram.min=1,
                                  ngram.max=3,
                                  stem=FALSE,
                                  rm.stopwords=TRUE,
                                  rm.whitespace=TRUE,
                                  rm.punctuation=TRUE,
                                  filter=NULL,
                                  filter.thres=NULL
                                  )

\end{lstlisting}

The \texttt{doc.list} object takes the form of a list containing four
objects:
\begin{itemize}
\item \texttt{vs.out}, the document-term matrix represented as a
  sparse \texttt{dgCMatrix} object
\item \texttt{idx.final}, an integer vector of row indices
  representing documents in the final bill
\item \texttt{idx.initial}, an integer vector of row indices
  representing documents from the initial bill
\item \texttt{idx.amendments}, an integer vector of row indices
  representing documents from the proposed amendments
\end{itemize} 

With the document-term matrix, we can now map the final bill to its
potential matches in the initial bill and amendments. The function
\texttt{MapBills} takes as input the \texttt{doc.list} object and a
specification for the distance function. Here, we use
\texttt{CosineMat}, a version of the cosine distance
optimized for this use case by using matrix algebra to compute all
distances simultaneously. However, any function that returns a
distance matrix of the $N_{final} \times N_{compare}$, where the rows
are the sections of the final bill and columns the sections of the
potential matches, may be used. 

\begin{lstlisting}[language=R, numbers=none]
map.bills.cos <- MapBills(doc.list,
                          distance.fun="CosineMat"
                          )
\end{lstlisting}

\texttt{MapBills} returns an R data frame with five columns: the
section index of the final bill, and the section index and distance
measure of both the original bill match and the amendment match. We
can see a sample of that data frame here:

\begin{verbatim}
  bill2.idx bill1.idx bill1.dist amend.idx amend.dist
2         2         6  0.2377064       980  0.7196255
3         3         3  0.7177070       980  0.3880453
4         4         4  0.5805601       981  0.6782620
5         5        24  0.1116871        94  0.8236878
6         6         4  0.1034507        95  0.9701425
\end{verbatim}

Before we identify the most likely set of matches based on these
distance metrics, we want to pick the optimum threshold value as
discussed on section \ref{sec:extens-negot-cont}. To do so, we will
use a hand-coded set of best matchs. The \texttt{leghist} package
provides three tools for doing so. First, the user may encode the best
match from the set of candidates using the same structure used by
\texttt{MapBills}. The \texttt{RunEncoder} routine allows the user to
encode a randomly-sampled portion of the final bill. It presents the
user with a set of candidate matches, based on likely matches from
both the initial bill and amendments. The user provides the index of
the best match, or \texttt{NA} if no valid match is
available.\footnote{We note that users who do not want to use the
  automated matching tools may still use the encoding tools to
  hand-match amendments. The tools reduce the set of possible matches
  to a set of likely matches based on the same vector space language
  representation used by the automated match algorithms, thereby
  reducing the search space for hand-coded matches.} Figure
\ref{fig:encoder-interface} provides a sample of the 
\texttt{RunEncoder} interface.

Based on the encoded sample, we may identify the optimum threshold
value based on the empirical accuracy of the matching algorithm. To do
so, we provide the \texttt{learn.threshold} interface. This takes as
one of its arguments a sequence of potential threshold values. It then
computes the accuracy of synthetic bill based on the output from \texttt{MapBills},
for each threshold value, and returns the optimum threshold value from
the sequence. The optimum
threshold value may be identified in two ways based on the
\texttt{type} argument. With \texttt{type=overall},
the aggregate accuracy of the matched pairs is estimated, and the
threshold value corresponding to the highest accuracy returned. With
\texttt{type=tradeoff}, the Type 1/2 error tradeoff (rate of correct
matches to amendments, versus rate of correct findings of ``no match'') is estimated and
the threshold value at the intersection of the type 1 and type 2 error
curves is returned. We recommend that the threshold sequence be
specified at a fairly granular level, such as \texttt{seq(0, 0.5, 0.005)}.

Figure \ref{fig:learn-threshold-output} shows the
output of both versions of this function as trained on a 30\% sample
of the bill in question. We can see that the optimum choice of
threshold value is about 0.3, such that any matches with simliarity
values $s < 0.3$ should be treated as ``no match''.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.75\textwidth]{intl_2007_accuracy_curves.pdf}
  \caption{Accuracy curves as returned from the \texttt{learn.threshold} function. Notice that the optimum threshold value is closer to the accuracy curve than the type 1/2 tradeoff curve intersection, owing to the relative flatness of the tradeoff curves.}
  \label{fig:learn-threshold-output}
\end{figure}

With an optimum threshold in mind, we can now build the most likely
composite on the basis of the matched
bill. \texttt{GetLikelyComposite} provides functionality for doing
so. As we can see, this takes a series of arguments: the output from
MapBills, the plain text used to create the original \texttt{doc.list}
object, and a series of labels that indicate from where the
amendments came (in this case, the Parliamentary committees from the
first reading, the Parliamentary second reading, and the European
Commission). The argument \texttt{dist.threshold} represents the decision threshold $T$ described in section
\ref{sec:extens-negot-cont}. If the program is unable to find a ``best match'' whose
distance to the target section of the final document exceeds that
value, it will insert the same section of the "final" bill as the best
match. This can be used to identify sections of the bill with
uncertain origins, which perhaps arose outside of the formal amendment
process. 


\begin{lstlisting}
  composite.bill.cos <- 
    GetLikelyComposite(map.bills.cos,
                       initial.bill,
                       final.bill,
                       c(ep.first.reading$text,
                       ep.second.reading$text,
                       commission.proposal
                       ),
                       c(ep.first.reading$committee,
                       rep("Parliament 2nd Reading", 
                            nrow(ep.second.reading)
                          ),
                       rep("Commission 2007",
                       length(commission.proposal)
                       )
                       ),
                       filter="max",
                       dist.threshold=0.2
                       )
                       
\end{lstlisting}

Finally, we may wish to write out a side-by-side comparison of the
actual final bill with the ``best match'' synthetic version returned
by \texttt{GetLikelyComposite}. The 
\texttt{WriteSideBySide} function provides an interface for building a
2-columna \LaTeX document with that comparison. Margin notes indicate the source of the
matched paragraph, its index number, and the distance or similarity
measure for its match to the target paragraph in the final
bill. Sample PDF output is shown in figure \ref{fig:pdf-output}.

\begin{lstlisting}[language=R]
write.side.by.side.cos <- 
   WriteSideBySide(composite.bill.cos,
                   final.bill,
                   cavs.out=doc.list,
                   file.out="ep_2007_intl_mkt_sbs_cos.tex",
                   dir.out="./2007/tex/",
                   pdflatex=TRUE
                   )
\end{lstlisting}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.75\textwidth]{sample_pdf_output}
  \label{fig:pdf-output}
  \caption{Sample PDF output from the \texttt{WriteSideBySide} function, for the 2009 European energy market reform legislation.}
\end{figure}

\section{Accuracy trials}
\label{sec:accuracy-trials}

We assess the accuracy of the matching algorithm against two different
standards: a human-matched document and the legislative record of
adopted amendments. The human-matched document makes use of the
\texttt{Encoder} tools provided in \texttt{leghist}. These tools take
as input the same set of documents provided to the matching algorithm,
generate a set of candidate matches for each section in the final
bill, and provide a user interface to indicate which of the candidate
matches is in fact the best match. A sample of the user interface,
running in the R console, is show in figure \ref{fig:encoder-interface}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{encoder}
  \caption{Sample of the \texttt{Encoder} interface, running in the R console. }
  \label{fig:encoder-interface}
\end{figure}

For the legislative record, we used the record of European
Parliamentary debate for the 2009 renewable energy law reform reform. The EU process
provides a particularly interesting test of the tools given its
somewhat convoluted process. After the Commission proposes legislation
to the Parliament, one or more committees can propose amendments,
which are numbered $1:N$ for each committee. Some subset of those
amendments are adopted, but the final adoption record does not
explicitly number the amendments or provide a mapping from the new
legislative document to the amendments. The Commission then indicates
which amendments it considers acceptable. The revised legislation and
the Commission's comment document are then taken up by the Council,
which can also amend the document. The Council, however, provides no
record of its internal proceedings and does not indicate, in the
version of the legislation it produces, which sections it
changed. Finally, the Parliament can conduct a second reading, where
it can again propose amendments. Those amendments may represent
agreed-upon changes to the bill arrived at through negotiation with
the Council, or new amendments. The final bill, ultimately, provides
no indication of which, if any, of these amendments were
adopted. Furthermore, subtle changes in language may occur to any
section of the bill, or to accepted amendments, during the legislative
process. 

For testing against the human-matched document, a user coded matches
for all 380 paragraphs of the final bill, using the interface shown in
figure \ref{fig:encoder-interface}. Possible origins for the final
bill included the 2001 renewable energy law which was being amended;
the Commission proposal for amendment; and the European Parliament's
First Reading Report. We note that the bill also underwent review by
the Council, which made other, non-specified changes. 

This user-encoded bill was then compared to the algorithmic match
across a range of threshold values, using the \texttt{LearnThreshold}
tools. Figure \ref{fig:rese-accuracy-test} shows the results of those
comparisons. For a threshold value of 0.45, the algorithm correctly
identified and matched amendments in 84\% of cases. While the rate of
correct source + index matching was lower, examination of the matches
shows that this discrepancy is due to two phenomena: first, some
amendments were offered multiple times with the same language; and
second, in some cases post hoc examination of human and algorithmic
matches showed that the algorithm found a closer match than the human
coder.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.75\textwidth]{rese_2007_accuracy_curves_full}
  \caption{Algorithm accuracy as a function of the similarity threshold value. Baseline for comparison is a fully human-encoded bill. Source accuracy indicates where the algorithm identified the same source (amendment, original bill, or final bill) as the human coder. Source + index accuracy indicates where the algorithm found both the same source and the same index value (e.g. Amendment 24) as identified by the human coder.  }
  \label{fig:rese-accuracy-test}
\end{figure}

\section{Content modeling}
\label{sec:content-modeling}

Finally, given the number of potential changes, we may wish to
summarize the content of those changes. This may not, of course,
capture subtle changes to wording that make large differences to the
impact of legislation. But it can help identify issue areas or policy
domains in which the legislative process made or failed to make
broader changes. It can also help identify areas of contention within
the broader domain of legislation. 

The \texttt{leghist} package provides the \texttt{ModelDocSet}
function as an interface to topic model capabilities in the
\texttt{topicmodels} package \citep{grun2011topicmodels}. These, in
turn, provide R interfaces to the Latent Dirichelet Allocation methods
implemented by \cite{blei2003latent} and
\cite{blei2006correlated}. These methods infer a set of topics from
the term distributions over a set of documents, on the assumption that
topics are differentiated by different distributions over a set of
terms. \texttt{ModelDocSet} provides the ability to feed one of five
subsets of documents to these models: the included or rejected
amendments (\texttt{incl.amend}, \texttt{rej.amend}); the surviving or rejected portions of the original
bill (\texttt{incl.orig}, \texttt{rej.orig}); and the portions that
were determined to have no valid match (\texttt{final}). 

\begin{lstlisting}[language=R, numbers=none]
model.incl.amend <- ModelDocSet(doc.list,
                                composite.bill.cos,
                                type="incl.amend",
                                k=5,
                                control=list(seed=2342)
                                )
model.rej.amend <- ModelDocSet(doc.list,
                               composite.bill.cos,
                               type="rej.amend",
                               k=5,
                               control=list(seed=2342)
                               )
\end{lstlisting}

We also provide a hierarchical interface, first clusters document
sections into semantically-related groups, and then clusters the
documents inside each cluster into semantic sub-groups. This
functionality implements the following intution: consider a group of
amendments and bill sections classified as "procedural" and identified
because of the predominance of terms like "audit", "budget",
"monitor", and "oversight". We would expect that, within that cluster,
we would observe that different amendments focus on different aspects
of these procedural elements of legislation. Hence sub-clustering
provides a means of breaking down bills and amendments into a sensible
2-level semantic hierarchy. Analysts could, of course, iterate this
process for any desired level of hierarchy. 

We also provide a means of tabulating the committee contributions by
both primary and secondary topic areas. The
\texttt{ctab.amend.hierarchy} function takes the output from
\texttt{model.amend.hierarchy} and returns the nested cross-tabulation
of committee contributions to each semantic cluster and subcluster. 

\begin{lstlisting}[language=R, numbers=none]
## Define the number of primary topics
k.main <- 8
rese.topics.2007 <- 
   ModelAmendHierarchy(doc.list.2007,
                       rese.composite.2007,
                       k=c(k.main, rep(5, k.main)),
                       addl.stopwords=c("article",
                         "paragraph", "follow", "replace",
                         "insert",
                         "ensure", "regulation",
                         as.character(0:9),
                         "commission",
                         "directive", "annex",
                         "parliament",
                         "council",
                         "alia", "whereas",
                         "january", "december", "july",
                         "deleted", "added", "amend",
                         "draft", "http", "mso",
                         "allowincell", "textbox",
                         "endiftextbox", "div"),
                       n.terms=10,
                       ngram=1,
                       sampling.method="VEM",
                       topic.method="CTM",
                       control=list(
                         var=list(tol=10^-4),
                         em=list(tol=10^-3),
                         seed=2342),
                       sparseness.probs=c(0.01, 0.999)
                       )


rese.topic.proportions.2007 <-
  CtabAmendHierarchy(rese.topics.2007,
                     rese.composite.2007,
                     committees.2007,
                     doc.list.2007,
                     tab.idx=2
                     )

\end{lstlisting}

Example output is shown below. We can quickly observe that the
Commission had, for instance, far more influence on amendments related
to topic 5, on specification and definition of renewable liquid fuels,
than the Parliament. Likewise, the Parliament exercised greater
influence over amendments in topic 6, governing the transfer of
renewable energy production credits among EU countries and between EU
countries and third parties. Likewise, we can see that within the
general set of regulations governing grid operators (topic 7),
different groups of amendments governed connection requirements,
administrative licensing and planning, emissions reduction and
renewable energy accommodation, and energy efficiency. These
inferences proceed in straightforward fashion from the
\texttt{leghist} workflow combining
an automated approach to legislative history tracking, and readily
available tools for semantic clustering of text. 

\begin{verbatim}
## Top ten words by influence for the 8-topic model
      [,1]             [,2]            [,3]            [,4]            
 [1,] "bioliquids"     "training"      "consumption"   "raw"           
 [2,] "countries"      "solar"         "share"         "support"       
 [3,] "significant"    "accordance"    "heat"          "materials"     
 [4,] "third"          "benefits"      "final"         "sustainability"
 [5,] "provided"       "adopted"       "target"        "schemes"       
 [6,] "sustainability" "share"         "overall"       "development"   
 [7,] "environmental"  "procedure"     "means"         "bioliquids"    
 [8,] "food"           "regulatory"    "mandatory"     "material"      
 [9,] "protection"     "certification" "set"           "environmental" 
[10,] "sustainable"    "appropriate"   "installations" "report"        
      [,5]        [,6]           [,7]           [,8]          
 [1,] "oil"       "origin"       "operators"    "fuels"       
 [2,] "values"    "transfer"     "table"        "emission"    
 [3,] "ethanol"   "guarantees"   "grid"         "resources"   
 [4,] "waste"     "competent"    "carbon"       "specific"    
 [5,] "process"   "accounting"   "require"      "savings"     
 [6,] "wood"      "body"         "distribution" "based"       
 [7,] "default"   "guarantee"    "procedures"   "efficiency"  
 [8,] "vegetable" "certificates" "transmission" "cogeneration"
 [9,] "biogas"    "issued"       "producers"    "information" 
[10,] "biofuel"   "compliance"   "rules"        "changes"
\end{verbatim}

\newpage
\begin{verbatim}
## Distribution of amendment acceptance and rejection
## by legislative actor and topic number
                            acc   rej
                                     
1 Commission               50.0   5.5
  Parliament 1st reading   50.0  94.5
2 Commission               61.8   8.0
  Parliament 1st reading   38.2  92.0
3 Commission               56.5   6.2
  Parliament 1st reading   43.5  93.8
4 Commission               54.5   4.5
  Parliament 1st reading   45.5  95.5
5 Commission               77.8  18.4
  Parliament 1st reading   22.2  81.6
6 Commission               36.1  21.2
  Parliament 1st reading   63.9  78.8
7 Commission               54.5   6.3
  Parliament 1st reading   45.5  93.7
8 Commission              100.0   6.7
  Parliament 1st reading    0.0  93.3
\end{verbatim}

\begin{verbatim}
## Primary and secondary topic features for topic 7 
[[7]]
[[7]]$terms.primary
 [1] "operators"    "table"        "grid"         "carbon"       "require"     
 [6] "distribution" "procedures"   "transmission" "producers"    "rules"       

[[7]]$terms.secondary
      Topic 1        Topic 2     Topic 3      Topic 4       Topic 5         
 [1,] "operators"    "table"     "procedures" "carbon"      "administrative"
 [2,] "grid"         "filled"    "equipment"  "wind"        "certification" 
 [3,] "costs"        "stroked"   "systems"    "economic"    "authorisation" 
 [4,] "transmission" "rectrect"  "conversion" "operators"   "licensing"     
 [5,] "distribution" "carbon"    "promote"    "information" "local"         
 [6,] "producers"    "unit"      "achieve"    "roads"       "planning"      
 [7,] "require"      "measured"  "efficiency" "offshore"    "applications"  
 [8,] "connection"   "stock"     "stock"      "development" "regional"      
 [9,] "regions"      "mass"      "carbon"     "impact"      "body"          
[10,] "rules"        "molecular" "annualised" "priority"    "established" 
\end{verbatim}


Finally, \texttt{leghist} provides several options for visualizing the
flow and semantic clustering of amendments. \texttt{PlotAmendsSuccess}
generates a directed acyclic graph representation of amendment flow
from its origins with legislative actors, via the topic clustering, to
either rejection or the final bill. Output for the renewable energy
legislation is shown in figure \ref{fig:amend-flow}. We observe that
while the Parliament's 1st reading supplied the majority of
amendments, the Commission's amendments were far more
successful. Overall, however, most amendments fail to pass into
law. As with the cross-tabulations, we can also see that topic six was
dominated by the Parliament, while the other topics saw equal
attention from both the Parliament and Commission.


\begin{lstlisting}[language=R, numbers=none]
PlotCommitteeTopics(rese.topics.2007, rese.composite.2007,
                    committees,
                    edge.width.scale=1, edge.width = "absolute",
                    scale.c=1, scale.t=1, scale.fin=1,
                    edge.transparency=75, edge.col=NULL,
                    main=NULL, arrowhead.size=0, 
                    layout=NULL, mid.layer=.65, 
                    plot.terms=TRUE, terms.cex=.5, terms.col="grey20",
                    terms.x.offset=0, terms.y.offset=0, 
                    terms.spread=1, terms.text.close=1,
                    labels=NULL
                    )
\end{lstlisting}

\begin{lstlisting}[language=R, numbers=none]
PlotAmendsSuccess(rese.topics.2007,
                  rese.composite.2007.cos,
                  committees.2007,
                  color.by="topics", col = NULL,
                  edge.width.scale=1, arrowhead.size=0,
                  af.shape="none", junk.shape="rectangle",
                  af.scale=1, junk.scale=1,
                  label.font=3,label.cex=.75, labels=NULL,
                  main="Amendments' Destinations",
                  legend.x=-1.25, legend.y=.5, legend.cex=.5
                  )
\end{lstlisting}

Likewise, \texttt{PlotAmendsSuccess} plots amendments by their final
destination as either accepted or rejected amendments. For accepted
amendments, they are mapped from the indexed list provided to their
location in the final bill. Figure \ref{fig:amend-dest} shows the
result for the renewable energy bill. We immediately notice large
sections of the final bill that do not have obvious origins in the
amendments. We can also observe that most amendments cluster by topic
within the successful bill. This provides visual confirmation of the
semantic coherence of different bill segments.

\begin{figure}[ht]
  \centering
  \includegraphics{plot_committee_topic_flow}
  \caption{Amendment origin, semantic clustering, and destination for the 2007 European Union renewable energy law. Edges represent amendment flow from sources to destination. Edge width reflects the share of amendments from that source bound for that destination. }
  \label{fig:amend-flow}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics{plot_amendment_destination}
  \caption{Amendment origin and destination by index. Edges reflect
    amendment flow from the original indexed list to the final bill or
  rejection. Colors reflect semantically clustered topics as output by
\texttt{ModelAmendHierarchy}.}
  \label{fig:amend-dest}
\end{figure}

\section{Conclusions}
\label{sec:conclusions}

The \texttt{leghist} package provides a range of utilities for
identifying the origin of sections of a final piece of legislation
given a set of possible sources. It further provides tools to analyze,
cluster, and visualize these matches. We hope that these tools will
prove useful to analysts of legislation and other documents in which
the process of document preparation is as important as the document
itself. 

We anticipate several useful extensions. A more elaborate document
retrieval process would perhaps improve on the quality of the
matches. Likewise, we might imagine a further set of algorithms that
help determine the optimal level at which to compare the final and
source documents, on the basis of some loss function. Finally, the
process presented here makes no use of positional information; the
fact that amendments are proposed to specific sections of a document
gets lost in the parsing stage. While the process of drafting
legislation destroys the value of a specific index, it does not
necessarily mean that a paragraph once at the center of a bill now
appears at the very end. Exploiting that information to restrict the
set of potential matches may improve overall match quality. Finally,
we are interested in, and hope to implement in future versions,
measures of semantic, rather than textual, similarity to quantify
differences in the degree of change implied by competing amendments to
the same section of a bill. 



\bibliography{/Users/markhuberty/Documents/Research/Papers/leghist/bib/leghist}
\bibliographystyle{apalike}
\end{document}
