* Design notes
1. Conceptual framework:
   For a piece of legislation L that goes through V versions L_v, and is
   subject to A proposed amendments, we would like to know how that
   legislation changes across the legislative cycle, which amendments
   were adopted, and whether they represent changes to substantive or
   administrative aspects of the law (i.e., what the law is intended
   to accomplish, versus how it should accomplish it). 
2. Automating this process would ideally return, for any two versions
   L_1 and L_2, several pieces of information:
   + A mapping of the sections of L_1 to their new location in L_2
   + A probabilistic indicator of the confidence of the map
   + A summary of the new content added
   + A summary of the content taken away
   + An indication of whether the changes were substantive or
     administrative
3. This implies several procedural steps:
   + Convert legislation to plain text and strip out any unnecessary information
   + Separate plain text into a set of individual "documents" that are
     at a sufficient level of granularity (paragraphs, perhaps?)
   + Do this for all versions to be compared
   + Construct a pairwise distance measure between each "document" in
     version 1 and each "document" in version 2
   + Select the "most likely" match and return it with a probability score
   + If amendments are provided, compare "not found" or low-prob match
     sections with amendments and return most likely amendment for
     that section
   + Return the original document, the matched sections of the new
     document
   + Run a topic model on stuff excluded from V1 in V2, new stuff in
     V2, amendments rejected, amendments accepted. 
   + Classify changes as substantive or administrative--perhaps based
     on a curated word list that would do well for administrative
     (i.e. "report" "enforce" "monitor" "transpose", etc)
   + For converting EU .docs to plain text, best way appears to be:
     save as .htm, then run lynx -dump <file> > output.txt. That
     strips the cruft out and leaves documents
     well-formatted. Produces (if a .doc is all that's available)
     about the same result as lynx -dump 'url.to.html.version' >
     output.txt. 
4. Some logic issues:
   + General structure:
     - first map bill_1:bill_2
     - then if(blank) map amend:blank
     - for chunk in bill2, take better match of bill1 and amend
     - Unless amend=delete? unclear how to handle this
   + Implementation
     - Need to construct the pairwise distance for all paras in bill1:2
     - And for amendments 1:2. These should produce lists of length bill2
     - Then take pairwise mins and return source (b, a) and index
     - Then retrieve correct chunk from amend or bill1 record w/ index
   + Should pass bills and amendments as lists; each element in the
     list is the string chunk vector. length(amendments) <
     (length(bills) - 1) so that you don't have more instances of
     amendments than you do of amending sessions. But amendments could
     be NULL. 
     - Then just loop across the bill structure--that way the function
       does both 2-version comparision and n-version comparison. 
     - To do this efficiently, pre-compute the corpuses so that only
       happens 1x for both the bills and amendments
5. Some parsing issues:
   + Right now, works well to do the following:
     + Get .doc
     + Convert to htm
     + Parse with python functions
   + This can also work if only the html is available, by saving the
     source, opening in MS Word, and then exporting to htm again
   + this is super-yucky but maybe the only universal way?
6. From Adrienne re the US process:
   + The process would be very beneficial if it looked like this:
     + Diff final:initial and final:amendments
     + Report mapping to all versions simultaneously (or,
       alternatively, just report the mapping of stuff that changes)
     + There are three versions that really matter inthe US congress:
       the initial bill, the substitute bill in committee, and the
       conference bill that comes out of the House / Senate
     + Would want to know (for the substitute bill in particular)
       which new parts mapped onto known amendments, and which new
       parts "sneaked in" along the way.
7. On writing out the tex file:
   + cat("\\macro{blah}") works just fine to write out plaintext.

* TeX issues
1. On writing out the tex file:
   + cat("\\macro{blah}") works just fine to write out plaintext.
2. Can box easily with the frame environment, need the framed
   package. Then it's just \begin{shaded} \end{shaded}, but need to
   define shadedcolor first, as in \definecolor{shadedcolor}{cmyk}{0,0.16,1,0}

* Unknowns:
  1. Correct distance measure
  2. Probabilistic measure--what's the probability derived from?
  3. What's the input to the topic model--the amendments themselves,
     the portions that were included / excluded, etc?
  4. How should classification be presented?

* TODO See Lee et al, "An Empirical Evaluation of Models of Text Document Similarity" for weighting /distance

* TODO LSA models for document similarity in R, the LSA package at CRAN: http://cran.r-project.org/web/packages/lsa/lsa.pdf
* Issue: this is basically plagiarism detection, but with some additional information (so the problem shouldn't be so hard). We should *expect* verbatim copying between the input and output documents, so we would improve accuracy to try and do something with the word order, etc. Right now, this isn't happening. Might need to first ID potential chunks in the docs, then match sequence?
  1. Taken from the Hoad and Zobel article from 2003-2004, looks like
     we should start from using cosine similarity and then implement
     their alternative (and in some cases better-performing)
     similarity measure that handles document length better. 
  2. Unsure how to manage this at the sentence level. This becomes
     somewhat problematic for US Congress amendment styles, which are
     based on clauses and substitutions rather than entire new paragraphs.

* Parsing the input data isn't going well. The template for the europarl amendments changed between 2003-2007 such that the tabular data now includes the Amendment header tag. This now means that the amendment extraction code needs to

* Possibility: dump file with w3m; then split each line at half line width; (Or, alternatively, get the position of the A in the amendment, and split from A:-1); also appears to work with MS-word generated HTML, but there's one problem--the Amendment tag doesn't show up in a standard place, so finding the right split is harder.

Pseudocode looks something like:
if clean_html
for row in doc:
    find first row with 'Text proposed by commission' and 'amendments
    by parliament'
    get index of amendment
else:
    idx is provided
    
for row in doc:
    if row is not empty and row does not contain <.*?>
         take row[idx:-1]

for row in doc:
    find rows with Amendment + number or Justification
    return [A|J, idx]

    ## This should return a list of lists, of form [A|J, idx]

for i in idx:
    if A, take rows in short rows from A:A+1
    if J, ignore 



    
    
* Thing to note: for the more advanced similarity measure, need to have a term vector that's the union of terms across all documents in bill1 + amendments. That means you need a pqrocess like:
1. Create DTM for bill2 + bill1 + amendments
2. Convert DTM to sparse matrix
3. Split DTM on index for bill2, bill1 + amendments

Then need to modify the MapBills code to do a single mapping against
bill1 + amendments and return best match to both. (Maybe by including
an index with the doclist output from createvectorspaces)


## Right now, the mod for mapfun doesn't work b/c the indexing is
## weird.
## Would be better to write mapfun like this:
## Mapfun(dtm.all, distance.fun, idx.final, idx.compare)
## Then can loop over idx.final and idx.compare
## without all the pre-processing. 
* Function design for matrix-like MapFun:
1. MapFun would take the entire doc-term matrix, the distance
   function, the row index of the final doc, and the row index of the
   query docs
2. Any distance function should take as input a matrix and two
   indices of length N and M, and return an M*N distance matrix where
   the cols are the "final" documents
3. The internals of the distance function don't matter so long as they
   return a matrix of the right form. 
4. The only outside issue is the fact that idx.compare = idx.initial +
   idx.amendments. Since I want to return both matches, I need to
   decompose the output distance matrix into "amendments" + "initial"


* Validation
- For the 2008 Intl Market bill, should note the correspondence
  between the output from leghist and the summary of what the
  Parliament proposed / was adopted in both the first and second
  plenaries. They correspond. Note, though, that the second plenary
  had far more to do with the agreement between the Council and
  Parliament, so it's not pure allocation. 

  http://www.europarl.europa.eu/oeil/popups/summary.do?id=1075365&t=d&l=en
